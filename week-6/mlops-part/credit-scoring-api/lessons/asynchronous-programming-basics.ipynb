{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ecbbde38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8523764b",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def task_one():\n",
    "    print(\"==Task One: Start\")\n",
    "    await asyncio.sleep(5)  # Simulating a non-blocking operation\n",
    "    print(\"==Task One: End\")\n",
    "\n",
    "async def task_two():\n",
    "    print(\"Task Two: Start\")\n",
    "    await asyncio.sleep(1)  # Simulating a non-blocking operation\n",
    "    print(\"Task Two: End\")\n",
    "\n",
    "async def main():\n",
    "    print(\"Main: Start\")\n",
    "\n",
    "    # Using asyncio.gather to run both tasks concurrently\n",
    "    await asyncio.gather(task_one(), task_two())\n",
    "\n",
    "    print(\"Main: End\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1876c482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main: Start\n",
      "==Task One: Start\n",
      "Task Two: Start\n",
      "Task Two: End\n",
      "==Task One: End\n",
      "Main: End\n"
     ]
    }
   ],
   "source": [
    "# Run the event loop to execute the asynchronous tasks\n",
    "await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "141e0409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fetching data from https://example.com/data1\n",
      "Start fetching data from https://example.com/data2\n",
      "Start fetching data from https://example.com/data3\n",
      "Finished fetching data from https://example.com/data1\n",
      "Finished fetching data from https://example.com/data2\n",
      "Finished fetching data from https://example.com/data3\n",
      "\n",
      "Results:\n",
      "Data from https://example.com/data1\n",
      "Data from https://example.com/data2\n",
      "Data from https://example.com/data3\n"
     ]
    }
   ],
   "source": [
    "async def fetch_data(url):\n",
    "    print(f\"Start fetching data from {url}\")\n",
    "    # Simulate a delay (representing network latency)\n",
    "    await asyncio.sleep(2)\n",
    "    print(f\"Finished fetching data from {url}\")\n",
    "    return f\"Data from {url}\"\n",
    "\n",
    "async def main():\n",
    "    # Using asyncio.gather to run multiple asynchronous tasks concurrently\n",
    "    results = await asyncio.gather(\n",
    "        fetch_data(\"https://example.com/data1\"),\n",
    "        fetch_data(\"https://example.com/data2\"),\n",
    "        fetch_data(\"https://example.com/data3\")\n",
    "    )\n",
    "    \n",
    "    print(\"\\nResults:\")\n",
    "    for result in results:\n",
    "        print(result)\n",
    "\n",
    "# Run the event loop to execute the asynchronous tasks\n",
    "await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "aed9c96e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading file1.csv...\n",
      "Downloading file2.csv...\n",
      "Downloading file3.csv...\n",
      "Processing CSV file1.csv: CSV data for file1.csv\n",
      "Processing CSV file2.csv: CSV data for file2.csv\n",
      "Processing CSV file3.csv: CSV data for file3.csv\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "\n",
    "async def download_csv(file_name):\n",
    "    '''\n",
    "    This has nothing to do with loading the CSV data via ex. pandas.\n",
    "    All this does is fetching the CSV file using some Python code.\n",
    "    That is why this is an I/O bounded task.\n",
    "    '''\n",
    "    # Simulate downloading a CSV (replace with actual download logic)\n",
    "    print(f\"Downloading {file_name}...\")\n",
    "    await asyncio.sleep(2)  # This just imitates the time it takes to download a file. \n",
    "                            # Introduces a delay of 2 seconds (because that is what sleep is doing, delaying.)\n",
    "                            # We start at t=0 and after 2 second are passed (the file is downloaded) then \n",
    "                            # we can do a preprocessing on the dataset, which also takes different time\n",
    "                            # and hence is also an asynchronous function and we need to await it.\n",
    "                            # Same story applies to fetch_and_process_csv which makes more clear of\n",
    "                            # what should be expected first (downloading) and then preprocessing right after\n",
    "                            # The main is also an asynchronous functiontion because we can possibly do something\n",
    "                            # after the main. Because main incorporates all the 'upper ladder' then it has\n",
    "                            # implicit \"awaiting\" factor. Hene await main()\n",
    "    return f\"CSV data for {file_name}\"\n",
    "\n",
    "async def process_csv(file_name, csv_data):\n",
    "    \"\"\"\n",
    "    So, while the downloading of the CSV data (await download_csv()) is an I/O-bound task, \n",
    "    the subsequent processing of the downloaded data (# Process the downloaded CSV data...) is where \n",
    "    CPU-bound operations may occur. If the processing logic involves heavy computations and you want \n",
    "    to take full advantage of multiple CPU cores, you might consider optimizing the CPU-bound portion.\n",
    "    Techniques like parallelization or using libraries optimized for numerical computations (e.g., NumPy) \n",
    "    could be explored depending on the nature of your processing tasks.\n",
    "    \"\"\"\n",
    "    # Process the downloaded CSV data (replace with actual processing logic)\n",
    "    print(f\"Processing CSV {file_name}: {csv_data}\")\n",
    "\n",
    "async def fetch_and_process_csv(file_name):\n",
    "    '''\n",
    "    This function just makes some logic of proper 'order' of which download and process should take place.\n",
    "    '''\n",
    "    # Run download_csv and process_csv concurrently for a single CSV file\n",
    "    csv_data = await download_csv(file_name)\n",
    "    await process_csv(file_name, csv_data)\n",
    "\n",
    "async def main():\n",
    "    # List of CSV files to fetch and process\n",
    "    csv_files = [\"file1.csv\", \"file2.csv\", \"file3.csv\"]\n",
    "\n",
    "    # Create tasks for fetching and processing each CSV file concurrently\n",
    "    tasks = [fetch_and_process_csv(file) for file in csv_files]\n",
    "\n",
    "    # Run tasks concurrently using asyncio.gather\n",
    "    await asyncio.gather(*tasks)\n",
    "\n",
    "await main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter-venv",
   "language": "python",
   "name": "jupyter-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
